---
title: "Homework on static labor supply"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(testthat)
require(xtable)
require(pander)
```

In the problem set we are following an labor supply model specefied by the following optimization problem. 

$$
\max_{c,h,e} c - \beta \frac{h^{1+\gamma}}{1+\gamma}\\
\text{s.t. } c = e \cdot \rho \cdot w\cdot h +(1-e)\cdot r \cdot  h
$$
The individual takes his wage $w$ as given, he chooses hours of work $h$ and consumption $c$. He also chooses whether to work in the labor force or to work at home where he has an equivalent wage $r$.

#### Problem 1 

The income effect means that as wages goes up, the individual will substitute away from wages a bit because they will now make the same amount of money in less amount of time. The way our problem is currently set up, as wages go up we will not see any income effect. This is because there is no concavity in C. The relationship with c is and our income is linear. 

 If we were to  substitute $c$ in the utility for $\frac{c^{1+\eta}}{1+\eta}$ then it is possible that we would see an income effect. Now our consumption is no longer linear in consumption but rather concave. This means, that as C increases there is a diminishing marginal return of increasing c even more. Therefore, when the individual has more income, rather than just continuing to increase c, they will choose to diminsh their hours somewhat.  


## Simulating data

We are going to simulate a data set where agents will choose participation as well as the number of hours if they decide to work. This requires for us to specify how each of the individual specific variables are drawn. We then set the following:

$$
\begin{align*}
\log W_i     &= \eta X_i + Z_i + u_i  \\
\log R_i     &= \delta_0 + \log(W_i) + \delta Z_i + \xi_i \\
\log \beta_i &= X_i +\epsilon_i +  a \xi_i   \\
\end{align*}
$$

and finally $(X_i,Z_i,\epsilon_i,u_i,\xi_i)$ are independent normal draws. Given all of this we can simulate our data. 

#### Problem 2 

The parameter a captures if there is a relationship between $r_i$ the amount of money the agent can make at home and $\beta_i$ the agent's distaste for work. If a is any value greater than zero then there is a relationship between $\beta_i$ and $r_i$. This will lead to an endogenity issue that will make it so we do not recover the correct value in our OLS estimation. 

The code below simulates the data when $a=0$ and when $a=1$ 

```{r, results='hide'}
library(data.table)
p  = list(gamma = 0.8,beta=1,a=0,rho=1,eta=0.2,delta=-0.2,delta0=-0.1,nu=0.5) # parameters
N=10000  # size of the simulation
simdata0 = data.table(i=1:N,X=rnorm(N))

# simulating variables
simdata0[,X := rnorm(N)]
simdata0[,Z := rnorm(N)]
simdata0[,u := rnorm(N)]
simdata0[,lw := p$eta*X  + Z + 0.2*u ]  # log wage

simdata0[,xi := rnorm(N)*0.2]
simdata0[,lr := lw + p$delta0+ p$delta*Z + xi]; # log home productivity

simdata0[,eps:=rnorm(N)*0.2]
simdata0[,beta := exp(p$nu*X  + p$a*xi + eps)]; # heterogenous beta coefficient

# compute decision variables
simdata0[, lfp := log(p$rho) + lw >= lr] # labor force participation
simdata0[, h   := (p$rho * exp(lw)/beta)^(1/p$gamma)] # hours
simdata0[lfp==FALSE,h:=NA][lfp==FALSE,lw:=NA]
simdata0[,mean(lfp)]

library(data.table)
p  = list(gamma = 0.8,beta=1,a=1,rho=1,eta=0.2,delta=-0.2,delta0=-0.1,nu=0.5) # parameters
N=10000  # size of the simulation
simdata1 = data.table(i=1:N,X=rnorm(N))

# simulating variables
simdata1[,X := rnorm(N)]
simdata1[,Z := rnorm(N)]
simdata1[,u := rnorm(N)]
simdata1[,lw := p$eta*X  + Z + 0.2*u ]  # log wage

simdata1[,xi := rnorm(N)*0.2]
simdata1[,lr := lw + p$delta0+ p$delta*Z + xi]; # log home productivity

simdata1[,eps:=rnorm(N)*0.2]
simdata1[,beta := exp(p$nu*X  + p$a*xi + eps)]; # heterogenous beta coefficient

# compute decision variables
simdata1[, lfp := log(p$rho) + lw >= lr] # labor force participation
simdata1[, h   := (p$rho * exp(lw)/beta)^(1/p$gamma)] # hours
simdata1[lfp==FALSE,h:=NA][lfp==FALSE,lw:=NA]
simdata1[,mean(lfp)]

```

Now that we have simulated our data both when $a=0$ and when $a=1$, we can see how when $a=1$ this affects our OLS estimation. 

```{r}
a1 <- lm(log(h) ~ lw + X, data=simdata1)
a0 <- lm(log(h) ~ lw + X, data=simdata0)
summary(a1)
summary(a0)
```
### Problem 3 

When $a=1$ we can a coefficient on log wages of 1.15, whereas when $a=0$ we got a coefficient of 1.248. We know that our coefficient of log wage should be $1 / \gamma$ so we should get a coefficient of about 1.25. Clearly, when $a=1$ there is an endogenity issue that is causing our coefficent to be wrong. 

Intution behind why, having $a=1$ we overestimate the value of $\gamma$
- when a is equal to 1 there is now a relationship between R and Beta 
- We only get to observe the people where wage > R. 
- If we assume there is no relationship between R and Beta then we are believing the people in our sample have some beta. 
- Because the people we observe are the people with smallers R's this must mean that these people also have smaller Beta's 
- Us believing that this people should have higher beta's than they actually do, leads to us overestimating the value of gamma. 

(I am gonna ask lamadon about this in office hours. )
(also the intercept)


## Heckman correction

As we have seen in class, Heckman (74) offers a way for us to correct the our regression in order to recover our structural parameters. 

As we have seen in class, we need to understand how the error term in the hour regression correlates with the laborparticipation decision. 

#### Problem 4 

$$
 E[\epsilon | log(\rho w) > log(r_i)] \\ 
 E[\epsilon | log(\rho w) > \delta_o + log(w_i) + \delta Z_i + \xi_i] \\ 
 E[\epsilon | log(\rho) > \delta_o + \delta Z_i + \xi_i] \\ 
$$
We know that $\epsilon_i$ and $\xi_i$ are jointly normal so we know $E[\epsilon | \xi_i] = a + b\xi_i$ 

$$
a + bE[\xi_i | \xi_i < log(p) - \delta_0 - \delta Z_i] + 0 
$$
Now we can construct the inverse mills ratio and incorporate that term in our regression to get rid of our endogenity issue. 

When we regress labor force particpation on $z_i$ we will find our coefficient2 $\beta_0 = \frac{log(\rho) - \delta_0}{\sigma_{\xi}}$ and $\beta_1 = \frac{\delta}{\sigma_{\xi}}$. Our Inverse Mills ratio can be seen below. 

$$ 

a - \frac{\sigma_{\xi} \phi( \frac{log(p) - \delta_0 - \delta Z_i}{\sigma_{\xi}})}{\Phi ( \frac{log(p) - \delta_0 - \delta Z_i}{\sigma_{\xi}})}
$$ 
When we add our inverse mills ratio into our regression we will do so by doing a probit of particpation on $Z_i$. We will call the two variables we recover from this regression as $\beta_0$ and $\beta_1$. When we add a term to our regression to account for this endogenity we will construct it as follows. 

$$
\frac{\phi(\beta_0 + \beta_1 * Z_i)}{\Phi(\beta_0 + \beta_1 * Z_i)}
$$

We will now run our regression with this additional term included in the regression. 

```{r}
fit2 = glm(lfp ~ Z,simdata1,family = binomial(link = "probit"))
Betas = summary(fit2)
B_0 = Betas$coefficients[1,1]
B_1 = Betas$coefficients[2,1]

simdata0[,lambda_i := pnorm(B_0 + B_1 * Z) / dnorm(B_0 + B_1 * Z)]

heck <- lm(log(h) ~ lw + X + lambda_i , data=simdata0)
summary(heck)




```

####Problem 5 

If we run the regression no including the variable we constructed above we get a coefficient on log wage of 1.248. We have now by including the inverse mills ration in our regression recovered the correct estiamte for $\gamma$ even in the case where $a\neq 0$.

## Repeated cross-section

```{r}
p  = list(gamma = 0.8,beta=1,a=0,rho=1,eta=0.2,delta=-0.2,delta0=-0.1,nu=0.5) # parameters
N=10000  # size of the simulation
simdatac1 = data.table(i=1:N,X=rnorm(N))

# simulating variables
simdatac1[,X := rnorm(N)]
simdatac1[,Z := rnorm(N)]
simdatac1[,u := rnorm(N)]
simdatac1[,lw := p$eta*X  + Z + 0.2*u ]  # log wage

simdatac1[,xi := rnorm(N)*0.2]
simdatac1[,lr := lw + p$delta0+ p$delta*Z + xi]; # log home productivity

simdatac1[,eps:=rnorm(N)*0.2]
simdatac1[,beta := exp(p$nu*X  + p$a*xi + eps + 0.2*u)]; # heterogenous beta coefficient

# compute decision variables
simdatac1[, lfp := log(p$rho) + lw >= lr] # labor force participation
simdatac1[, h   := (p$rho * exp(lw)/beta)^(1/p$gamma)] # hours
simdatac1[lfp==FALSE,h:=NA][lfp==FALSE,lw:=NA]
simdatac1[,mean(lfp)]

```

```{r}
p  = list(gamma = 0.8,beta=1,a=0,rho=1.2,eta=0.2,delta=-0.2,delta0=-0.1,nu=0.5) # parameters
N=10000  # size of the simulation
simdatac2 = data.table(i=1:N,X=rnorm(N))

# simulating variables
simdatac2[,X := rnorm(N)]
simdatac2[,Z := rnorm(N)]
simdatac2[,u := rnorm(N)]
simdatac2[,lw := p$eta*X  + Z + 0.2*u ]  # log wage

simdatac2[,xi := rnorm(N)*0.2]
simdatac2[,lr := lw + p$delta0+ p$delta*Z + xi]; # log home productivity

simdatac2[,eps:=rnorm(N)*0.2]
simdatac2[,beta := exp(p$nu*X  + p$a*xi + eps + 0.2*u)]; # heterogenous beta coefficient

# compute decision variables
simdatac2[, lfp := log(p$rho) + lw >= lr] # labor force participation
simdatac2[, h   := (p$rho * exp(lw)/beta)^(1/p$gamma)] # hours
simdatac2[lfp==FALSE,h:=NA][lfp==FALSE,lw:=NA]
simdatac2[,mean(lfp)]
```


```{r}
fitcs1 = glm(lfp ~ Z,simdatac1,family = binomial(link = "probit"))
Betas = summary(fitcs1)
B_01 = Betas$coefficients[1,1]
B_11 = Betas$coefficients[2,1]

fitcs2 = glm(lfp ~ Z,simdatac2,family = binomial(link = "probit"))
Betas = summary(fitcs2)
B_02 = Betas$coefficients[1,1]
B_12 = Betas$coefficients[2,1]

```

####Problem 6 
- our intercept terms are super different 


Lastly we want to replicate the approach of Blundell, Duncan and Meghir. To justify such an appraoach we are going to include an additional endogeneity concern between the wage and the disutility of hours of worked. We want to do the following:

 1. add the wage residual $u_i$ inside the expression for $\beta_i$ (similar to the $\xi$ term)
 2. simulate 2 data-sets (two different cross-sections, redraw everything). However in the second cross-section change the $rho$ to 1.2

Our final step is then to try to recover the wage elasticty by differencing across periods usig the tax variation. To do so, we need to compute time specific Mills ratios. 

<span class="label label-success">Question 6</span> Why do we need to estimate the parameters of the selection equation separatly for each period? 

<span class="label label-success">Question 7</span> Create the heckman correction term for each observation in each period. Then cut the X into a few values (picking some threshold). Finally compute all first difference in the time dimension (including the mills ratio difference). Finally run the regression using the different group as obervations and the difference as variables. Do this allow to recover the correct $\gamma$?






