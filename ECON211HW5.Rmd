---
title: "Homework on unobserved hetereogeneity"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: no
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(ggplot2)
library(texreg)
library(readstata13)
library(sandwich)
options(knitr.table.format = "html") 
library(data.table)
library(plm)
library(lmtest)
library(rlist)
```

# A Simple Model 
### Question 1 
### Question 2
#Simulating data 

```{r}
p = list(rho=0.9,a = 3, gamma =1.5)
p$n = 1000
data = data.table(B = 0, W = exp(rnorm(p$n) -3))

# solve for lambda
data[, Lb := ((p$rho*W - B)/(p$a))^(1/(1+p$gamma))]
data[, Lb := pmin(pmax(Lb,0),1)]

data[, D  := rexp(p$n, rate = Lb)]

ggplot(data,aes(x=W,y=Lb)) + geom_line() + theme_bw()
```


# Estimating 
### Question Three 

```{r}
lam = function(a, gamma, rho=0.9, W, B=0) {((rho*W - B) / a)^(1/(1+gamma))}

a = seq(2.5, 3.5, .001)
g = seq(1, 2, .001)
grid = expand.grid(a,g)


lik.homo = function(W, D, grid) {
  n = length(W)
  a = grid["Var1"]  
  gamma= grid["Var2"] 
  lambda = lam(a, gamma, p$rho, W)
  likelihood = (log(lambda) * n - (lambda*sum(D))) 
  index = which.max(likelihood)
  return(grid[index,])
}
lik.homo(data$W,data$D,grid)
```

### Question Four 
# Random Effect 
### Question 5 
```{r}
p = list(rho=0.9, a = c(1,3,5), gamma =1.5, pk = c(0.2,0.5,0.3))

p$n = 1000
data = data.table(B = 0, W = exp(rnorm(p$n) - 2))

# draw the latent type
data[, k := sample.int(3,.N,prob = p$pk,replace=T)]

# solve for lambda
data[, Lb := ((p$rho*W - B)/(p$a[k]))^(1/(1+p$gamma))]
data[, Lb := pmin(pmax(Lb,0),1)] # bound it between 0 and 1

data[, D := rexp(p$n, rate = Lb)]
```

```{r}
lik.homo.i = function(W, D, pk, a, gamma){
  lambda = lam(a, gamma, .9, W, 0)
  return(sum(pk * lambda * exp(-lambda * D)))
}

lik.homo.k = function(W, D, pk, a, gamma) { 
  i_s = mapply(lik.homo.i, W, D, MoreArgs = list(pk = pk, a = a, gamma = gamma))
  return(sum(log(i_s)))
}

lik.homo.k(data$W,data$D, p$pk, p$a, p$gamma)

g = seq(1, 1.8, .1)
a1 = seq(.8, 1.3, .1)
a2 = seq(2.8, 3.3, .1)
a3 = seq(4.8, 5.3, .1)
p1 = seq(0, 1, .1)
p2 = seq(0, 1, .1)
grid = expand.grid(g, a1, a2, a3, p1, p2)
colnames(grid) <- c("g", "a1", "a2", "a3", "p1", "p2")
grid['p3'] = 1 - grid$p1 - grid$p2 
grid = grid %>%
    filter(p3 >= 0)

maxlik = function(grid, W, D){
  # likely = mapply(lik.homo.k, W, D, cbind(p1, p2, p3), cbind(a1, a2, a3), g)
  # return(lik.homo.k(W, D, cbind(p1,p2,p3), cbind(a1, a2,a3), g))
  likely = rep(0, nrow(grid))
  
  for (i in 1:nrow(grid)){
    pk = cbind(grid$p1[i], grid$p2[i], grid$p3[i])
    ak = cbind(grid$a1[i], grid$a2[i], grid$a3[i])
    likely[i] = lik.homo.k(W, D, pk, ak, grid$g[i])
  }

  ind = which.min(likely)
  return(grid[ind, ])
  }

t = maxlik(grid[sample(nrow(grid), 1000),], data$W, data$D); t

  
```


### Question 6 
``` {r EM_whatever}
# Do we need to recover the pks??
e_step <- function(g0, W, D){
  
}

```

### Question 7  
# Fixed Effect 
### Question 8 
```{r fixed_effects}

p = list(rho=0.9, gamma =1.5)
p$n = 1000
data = data.table(B = 0, W = exp(rnorm(p$n) -2))
# draw the latent type
data[, a := runif(p$n, min=0.5, max=2.5)]
# solve for lambda
data[, Lb := ((p$rho*W - B)/a)^(1/(1+p$gamma))]
data[, Lb := pmin(pmax(Lb,0),1)] # bound it between 0 and 1
data[, D := rexp(p$n, rate = Lb)]

best_ai <- function(w_i, D, g, B = 0, rho = p$rho){
  # check this - we average over all D? but W_i is individual-specific?
  return((rho * w_i - B)*((mean(D))^(1+g)))
}

likelihood_g <- function(g, W, D, B = 0, rho = p$rho){
  # evaluates likelihood at gamma = g
  
  a_opt = mapply(best_ai, W, MoreArgs = list(g=g, D=D))
  lambda = lam(a_opt, g, rho = 0.9, W)
  n = length(D)
  llhood = (n * log(lambda)) - (lambda*sum(D))
  
  return(llhood)
}

```
### Question 9 


